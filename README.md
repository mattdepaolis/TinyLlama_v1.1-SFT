# SFT TinyLlama Fine-Tuning
This repository contains a Jupyter notebook for fine-tuning the TinyLlama language model using SFT. The notebook is structured to guide you through the process of loading the model, setting up the environment, and performing the fine-tuning steps.

## Prerequisites
Before you begin, ensure you have the following installed:

Python 3.7 or higher
Jupyter Notebook or Jupyter Lab

## Installation

Clone this repository:

```bash
git clone https://github.com/mattdepaolis/TinyLLama_v1.1-SFT.git
cd TinyLLama_v1.1-SFT
```

## Usage
To run the notebook, execute the following command in your terminal:

```bash
jupyter notebook SFT_tinyLlama.ipynb
```

Follow the steps in the notebook to load the model, prepare your data, fine-tune the model, evaluate it, and save the results.

## Contributing
Contributions are welcome! Please fork the repository and submit a pull request for any improvements or additions.

## License
This project is licensed under the MIT License. See the LICENSE file for more details.
